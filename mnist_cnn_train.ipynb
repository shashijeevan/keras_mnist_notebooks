{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "\r",
      "  128/60000 [..............................] - ETA: 1:20 - loss: 2.3128 - acc: 0.0859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input1391\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.2634 - acc: 0.9190 - val_loss: 0.0580 - val_acc: 0.9813\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0870 - acc: 0.9746 - val_loss: 0.0463 - val_acc: 0.9843\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0655 - acc: 0.9804 - val_loss: 0.0343 - val_acc: 0.9886\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.0528 - acc: 0.9842 - val_loss: 0.0356 - val_acc: 0.9876\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0463 - acc: 0.9862 - val_loss: 0.0328 - val_acc: 0.9883\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0416 - acc: 0.9874 - val_loss: 0.0299 - val_acc: 0.9897\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0384 - acc: 0.9885 - val_loss: 0.0295 - val_acc: 0.9903\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0288 - val_acc: 0.9914\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0313 - acc: 0.9900 - val_loss: 0.0267 - val_acc: 0.9913\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0294 - acc: 0.9909 - val_loss: 0.0254 - val_acc: 0.9916\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0265 - val_acc: 0.9924\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 0.0247 - val_acc: 0.9927\n",
      "Test loss: 0.024676971391835105\n",
      "Test accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "#print(model.summary())\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
